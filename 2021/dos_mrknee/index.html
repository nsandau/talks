<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Presentation</title>
    <meta charset="utf-8" />
    <script src="index_files/header-attrs-2.11/header-attrs.js"></script>
    <link href="index_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
    </script>
    <style>
    .mjx-mrow a {
      color: black;
      pointer-events: none;
      cursor: default;
    }
    </style>
    <link rel="stylesheet" href="assets/fonts.css" type="text/css" />
    <link rel="stylesheet" href="assets/custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: title-slide
background-image: url("assets/ucph-logo-white-en.svg"), url("assets/suh-white-en.svg"), url("assets/title-knee-mri.jpg")
background-position: 8% 90%, 32% 89%, 100% 50%
background-size: 150px, 180px, 50% 100%
background-color: #0148A4

.pull-left[
&lt;br&gt;
## .text-shadow[.white[Using deep learning to diagnose knee injuries on magnetic resonance images: &lt;br&gt; current potential and limitations]]

### .white[**Nicolai Sandau**, MD &lt;br&gt; Stig Brorson, MD PhD DMSc]
&lt;br&gt;
### .white[Centre for Evidence-Based Orthopedics, Dept. of Orthopedic Surgery,&lt;br&gt;Zealand University Hospital]
]

???
Først vil jeg gerne sige tak for muligheden for at komme og fortælle om vores projekt hvor vi har udviklet en deep learning model de havde udviklet til at diagnosticere ACL og menisk skader ud fra MR scanninger. 
---

# Background
&lt;br&gt;
.center[
  .middle[
![:scale 60%](figures/orig_paper.png)
  ]
]

???
Baggrunden for dette projekt kommer fra en artikel udgivet i 2018 hvor en gruppe fra Stanford præsenterede deres resultater for en deep learning model der kunne diagnosticere ACL og menisk skader ud fra MR billeder. 

I artiklen sammenlignede de deres model med radiologer, men de måtte  konkludere at deres model ikke helt var på niveau med radiologernes.  

Deep learning feltet har de seneste år oplevet en massiv teknologisk udvikling. 
Vi ville med dette projekt derfor undersøge om det ved hjælp af disse fremskridt var muligt at opnå resultater på niveau med radiologer. 

---

# Methods: Data

- 1250 cases 
  - Training: 1130 
  - Validation: 120

.pull-left[
.center[
![:scale 50%](figures/coronal_1_img.png)]]

.pull-right[.center[
&lt;div class="math"&gt;
\[
\begin{array}{cc} &amp;
\\
&amp;
\left(
\begin{array}{ccc}
1 &amp; 203 &amp; 130 &amp; 26 &amp; 62 &amp; 43 \\
206&amp; 51 &amp; 120 &amp; 40 &amp; 18 &amp; 5 \\
0 &amp; 53 &amp; 231 &amp; 102 &amp; 158 &amp; 191 \\
31 &amp; 41 &amp; 99 &amp; 156 &amp; 224 &amp; 139 \\
209 &amp; 79 &amp; 153 &amp; 156 &amp; 168 &amp; 89 \\
72 &amp; 132 &amp; 83 &amp; 65 &amp; 134 &amp; 230 \end{array}
\right)\end{array}
\]
&lt;/div&gt;]]

???
Vi benyttede det samme dataset som de brugte i artiklen fra 2018 som består af i alt 1250 cases.
De 1250 cases er delt op i et trænings sæt og et validerings. 
Valideringssættet benyttes til at teste modellen på et sæt billeder den aldrig har set før. 

Hver case var klassificeret med diagnose af meniskus og/eller acl skader. 

Som man kan se nederst på sliden så er billederne blot en matrix af tal. 
Og grundlæggende så forsøger en deep learning model at finde en transformation af de her tal på en sådan måde at den kan skelne mellem billeder med en skade fra dem uden. 

Så der er lidt forsimplet to måder man kan forbedre sådan en model: 
1. ved at optimere forarbejdelsen af den data som modellen trænes på
2. optimere de transformationer som modellen kan lære, også kaldet arkitekturen af modellen

---
# Methods: Deep learning model

&lt;br&gt;

.center[
.middle[
  ![:scale 65%](figures/training.svg)
]]

???

Det skal gøres for hvert plan individuelt, således at hver model er trænet i isolation. 
Til sidst kombinerer man så sandsynlighederne fra hvert plan ved hjælp af en simpel logistisk regression og man opnår derefter en vægtet sandsynlighed for at den her patient har en diagnose.  

Det her gjorde vi så for både ACL og for menisk. 
---

# Results: ACL 
&lt;br&gt;

.center[.middle[
![:scale 55%](figures/roc_acl.svg)
]]

???
Idet modellen giver en sandsynlighed for en given diagnose kan man anvende en såkaldt reciever operator curve hvor vi har den sande positiv rate på y-aksen og den falske positiv rate på x-aksen.

Ved at justere hvor sikker modellen skal være på en diagnose kan man justere på de to parametre som illustreret ved den sorte streg. Dvs jo mere sikker modellen skal være nedsætter vi den falske positive rate men det er på bekostning af den sande positive rate. 

Et overordnet mål for præstationen er så arealet under kurven hvor det maksimale er 1, svarende til at man havde en sand positiv rate på 1 og en falsk positiv rate på 0.

Når man beregner sensitivitet og specificity er cut-off normalt 0.5 som for vores model er illustreret med den grønne plet.   

Til sammenligning kan man se modellen fra den førnævnte artikel svt det røde punkt, samt radiologernes resultater fra samme artikel i det blå punkt. 

---
# Results: Meniscus
&lt;br&gt;

.center[.middle[
![:scale 55%](figures/roc_men.svg)
]]

???
For meniskskader kan vi se at modellen igen er sammenlignelig med radiologernes diagnosticeringsevne. 
---

# Results: GradCAM

&lt;br&gt;

.center[.middle[
    ![:scale 50%](figures/gradcam.png)
  ]
]

???
Når modellen træner kan man trække de tal ud som den bruger til at justere sine parametre og overlægge dem som et heatmap på de billeder som den har trænet på for at få et indblik i hvilke regioner modellen tillæger størst vægt og som det kan ses ser det ud til at den har en god ide om hvilke områder der adskiller patienterne med og uden skader. 

Labels: no acl tear or meniscus tear
---

# Limitations
.Large[
* Lack of generalizability 
  * Patient population 
  * Different scanners
  * Other pathologies
* Potential solution: More high quality data
]
???
Som med de fleste andre statistiske modeller, er der dog nogle begrænsninger man skal have in mente hvoraf den største er i forhold til til generaliserbarheden 
Idet modellen kun  kender til de cases den har trænet på skal man sikre sig at de patienter man træner på er fra samme population som den man vil anvende den på. 
Som eksempel var det her dataset fra et amerikansk hospital hvor man kan se at mange har hæmartron sandsynligvis fordi de bliver scannet umiddelbart efter skadens indtræden. 
Modellen kan derfor formentlig ikke direkte overføres her til Danmark, da patienterne formentlig bliver scannet på et senere tidspunkt og færre måske derfor har hæmartron.
Dette gælder også i forhold til anvendelsen af forskellige scannere eller hvis patienterne har andre patologier udover dem som modellen er trænet på.

En potentiel løsning er mere data af høj kvalitet. 
I det her tilfælde med menisk og acl skader er der især behov for intra-operativt verificerede diagnoser, da som vi kunne se, også radiologer tager fejl når de vurderer MR scanninger. 
Og modellen kan kun være så god som den data den har lært fra.  

---
# Conclusions

.Large[
* Deep learning methods has the potential to aid radiologists and orthopedic surgeons in the diagnosis of meniscus and ACL injuries on MRI. 
* More high quality data is needed to improve generalizability.
]

???
Deep learning modeller har potentiale til at kunne bidrage i diagnosticeringen af menisk og acl skader men der er behov for mere højkvalitets data for at sikre generaliserbarheden inden vi kan se det implementeret i klinisk praksis. 

---
class: sydney-blue
background-image: url(assets/USydLogo-white.svg)
background-size: 260px
background-position: 5% 95%

# .white[Thank you!]

.pull-right[.pull-down[
Nicolai Sandau, MD &lt;br&gt;
Centre for Evidence-Based Orthopedics, &lt;br&gt; 
Dept. of Orthopedic Surgery, &lt;br&gt;
Zealand University Hospital, &lt;br&gt;
Denmark &lt;br&gt;
&lt;a href="mailto:nicsa@regionsjaelland.dk"&gt;
.white[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg> nicsa@regionsjaelland.dk]
&lt;/a&gt;

&lt;br&gt;&lt;br&gt;

]]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="assets/img_scale.js"></script>
<script src="assets/remark-zoom.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
